import os
from slack_bolt import App
from langchain import  LLMChain
from langchain.prompts import PromptTemplate
from openai import OpenAI
from dotenv import load_dotenv
from langchain.chat_models import ChatOpenAI



load_dotenv()


SLACK_BOT_TOKEN = os.getenv("SLACK_BOT_TOKEN")
SLACK_SIGNING_SECRET = os.getenv("SLACK_SIGNING_SECRET")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

app = App(token=SLACK_BOT_TOKEN, signing_secret=SLACK_SIGNING_SECRET)


template = """ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã‚¿ã‚¹ã‚¯ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ï¼š
- ã‚¿ã‚¤ãƒˆãƒ«: {{task}}
- ç· ã‚åˆ‡ã‚Š: {{due}}
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›: ã€Œ{user_input}ã€"""

prompt = PromptTemplate(input_variables=["user_input", "task", "due"], template=template)
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.2, openai_api_key=OPENAI_API_KEY)
chain = LLMChain(llm=llm, prompt=prompt)

@app.command("/add-task")
def handle_add_task(ack, body, say):
    ack()
    text = body["text"]  # ä¾‹: "è³‡æ–™ä½œæˆ æ˜æ—¥ã¾ã§"
    task, due = text.split(" ", 1)
    result = chain.run(user_input=text, task=task, due=due)
    say(f"ã‚¿ã‚¹ã‚¯è¿½åŠ ã—ãŸã‚ˆã£ğŸ’•\n{result}")

if __name__ == "__main__":
    app.start(port=int(os.getenv("PORT", 3000)))